{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import resnet.resnet as resnet\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from model import Net\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) # Cleaner demos : Don't do this normally..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['name', 'tracker', 'config', 'weights', 'eval', 'vocab'])\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "state_path = '../2017-08-04_00.55.19.pth'\n",
    "saved_state = torch.load(state_path)\n",
    "print(saved_state.keys())\n",
    "qtoken_to_index = saved_state['vocab']['question']\n",
    "answer_words = ['UNDEF'] * len(saved_state['vocab']['answer'])\n",
    "print(len(answer_words))\n",
    "for w,idx in (saved_state['vocab']['answer']).items():\n",
    "    answer_words[idx]=w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_tokens):\n",
    "        super().__init__()\n",
    "        self.module = Net(embedding_tokens)\n",
    "    \n",
    "    def forward(self, v, q, q_len):\n",
    "        return self.module.forward(v, q, q_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet152(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = resnet.resnet152(pretrained=True)\n",
    "\n",
    "        image_size = 448\n",
    "        # output_features = 2048\n",
    "        central_fraction = 0.875\n",
    "\n",
    "        self.transform = get_transform(image_size, central_fraction)\n",
    "\n",
    "        def save_output(module, input, output):\n",
    "            self.buffer = output\n",
    "        self.model.layer4.register_forward_hook(save_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.model(x)\n",
    "        return self.buffer\n",
    "\n",
    "    def image_to_features(self, image_file):\n",
    "        img = Image.open(image_file).convert('RGB')\n",
    "        img_transformed = self.transform(img)\n",
    "        img_batch = img_transformed.unsqueeze(dim=0).to(device)\n",
    "        return self.forward(img_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(target_size, central_fraction=1.0):\n",
    "    return transforms.Compose([\n",
    "        transforms.Scale(int(target_size / central_fraction)),\n",
    "        transforms.CenterCrop(target_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_question(question_str):\n",
    "    tokens = question_str.lower().split(' ')\n",
    "    vec = torch.zeros(len(tokens)).long()\n",
    "    for i, token in enumerate(tokens):\n",
    "        vec[i] = qtoken_to_index.get(token, 0)\n",
    "    return vec.to(device), torch.tensor(len(tokens)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = WrappedModel(len(qtoken_to_index) + 1)\n",
    "model = torch.nn.DataParallel(Net(len(qtoken_to_index) + 1))\n",
    "model.load_state_dict(saved_state['weights'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "resnet152 = ResNet152().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_examples = [\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/banana.jpg',\n",
    "        'question': 'what is this fruit?',\n",
    "        'answer': 'banana'\n",
    "    },\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/apple.jpg',\n",
    "        'question': 'what is this fruit?',\n",
    "        'answer': 'apple'\n",
    "    },\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/gray.jpeg',\n",
    "        'question': 'what is this fruit?',\n",
    "        'answer': 'apple'\n",
    "    },\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/how many person in the image 1.jpg',\n",
    "        'question': 'how many person in the image ?',\n",
    "        'answer': 'one'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/how many person in the image 2.jpg',\n",
    "        'question': 'how many person in the image ?',\n",
    "        'answer': 'three'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/how many person in the image 3.jpg',\n",
    "        'question': 'how many person in the image ?',\n",
    "        'answer': 'four'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/how many person in the image 4.jpg',\n",
    "        'question': 'how many person in the image ?',\n",
    "        'answer': 'six'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/how many person in the image 5.jpg',\n",
    "        'question': 'how many person in the image ?',\n",
    "        'answer': 'seven'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/how many person in the image.jpg',\n",
    "        'question': 'how many person in the image ?',\n",
    "        'answer': 'five'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/is the child happy 1.jpg',\n",
    "        'question': 'is the child happy ?',\n",
    "        'answer': 'no'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/is the child happy.jpg',\n",
    "        'question': 'is the child happy ?',\n",
    "        'answer': 'yes'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/is there a sea in the image (1).jpg',\n",
    "        'question': 'is there a sea in the image ?',\n",
    "        'answer': 'yes'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/is there a sea in the image (1).png',\n",
    "        'question': 'is there a sea in the image ?',\n",
    "        'answer': 'yes'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/is there a sea in the image (1).webp',\n",
    "        'question': 'is there a sea in the image ?',\n",
    "        'answer': 'no'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/is there a sea in the image (10).jpg',\n",
    "        'question': 'is there a sea in the image ?',\n",
    "        'answer': 'yes'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/is there a sea in the image (11).jpg',\n",
    "        'question': 'is there a sea in the image ?',\n",
    "        'answer': 'no'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/is there a sea in the image (2).jpg',\n",
    "        'question': 'is there a sea in the image ?',\n",
    "        'answer': 'yes'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/is there a sea in the image (3).jpg',\n",
    "        'question': 'is there a sea in the image ?',\n",
    "        'answer': 'no'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/is there a sea in the image (4).jpg',\n",
    "        'question': 'is there a sea in the image ?',\n",
    "        'answer': 'yes'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/is there a sea in the image (5).jpg',\n",
    "        'question': 'is there a sea in the image ?',\n",
    "        'answer': 'yes'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/is there a sea in the image (6).jpg',\n",
    "        'question': 'is there a sea in the image ?',\n",
    "        'answer': 'yes'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/is there a sea in the image (7).jpg',\n",
    "        'question': 'is there a sea in the image ?',\n",
    "        'answer': 'yes'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/is there a sea in the image (8).jpg',\n",
    "        'question': 'is there a sea in the image ?',\n",
    "        'answer': 'no'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/is there a sea in the image (9).jpg',\n",
    "        'question': 'is there a sea in the image ?',\n",
    "        'answer': 'no'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/is there a sea in the image.jpg',\n",
    "        'question': 'is there a sea in the image ?',\n",
    "        'answer': 'yes'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/what dose the child do.jpg',\n",
    "        'question': 'what dose the child do ?',\n",
    "        'answer': 'sing'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/what is the color of child eyes.jpg',\n",
    "        'question': 'what is the color of child eyes ?',\n",
    "        'answer': 'blue'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/what is the color of child hair 1.jpg',\n",
    "        'question': 'what is the color of child hair ?',\n",
    "        'answer': 'black'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/what is the color of child hair.jpg',\n",
    "        'question': 'what is the color of child hair ?',\n",
    "        'answer': 'blonde'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/what is the color of the cat  (1).jpg',\n",
    "        'question': 'what is the color of the cat ?',\n",
    "        'answer': 'brown'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/what is the color of the cat  (2).jpg',\n",
    "        'question': 'what is the color of the cat ?',\n",
    "        'answer': 'black'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/what is the color of the cat  (3).jpg',\n",
    "        'question': 'what is the color of the cat ?',\n",
    "        'answer': 'gray'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/what is the color of the cat  (4).jpg',\n",
    "        'question': 'what is the color of the cat ?',\n",
    "        'answer': 'white'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/what is the color of the cat  (5).jpg',\n",
    "        'question': 'what is the color of the cat ?',\n",
    "        'answer': 'brown'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'img_path': 'C:/Users/mhala/Desktop/Projects/img/what is the color of the cat  (6).jpg',\n",
    "        'question': 'what is the color of the cat ?',\n",
    "        'answer': 'black'\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc_device_obj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m                 raise RuntimeError(\"module must have its parameters and buffers \"\n\u001b[0m\u001b[0;32m    148\u001b[0m                                    \u001b[1;34m\"on device {} (device_ids[0]) but found one of \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                                    \"them on device: {}\".format(self.src_device_obj, t.device))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('-'*50)\n",
    "for d in vqa_examples:\n",
    "    v = resnet152.image_to_features(d['img_path'])\n",
    "    q, q_len = encode_question(d['question'])\n",
    "    ans = model(v, q.unsqueeze(0), q_len.unsqueeze(0))\n",
    "    _, answer_idx = ans.data.cpu().max(dim=1)\n",
    "    print('question:', d['question'] , ', vqa answer:', answer_words[ answer_idx ], ', actuel answer:', d['answer'])\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bit5297959d06d94a8587308ced522bcaf9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
